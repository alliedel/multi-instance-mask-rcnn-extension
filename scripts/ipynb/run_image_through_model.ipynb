{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepaths to know of\n",
    "# Standard\n",
    "# config_filepath = f\"/home/adelgior/afs_directories/espresso/code/multi-instance-mask-rcnn-extension/output/logs/train/train_2021-06-17-095941_VCS-2dbaca2_MAX_ITR-100000_HEAD_TYPE-None/config.yaml\"\n",
    "# model_checkpoint = f\"/home/adelgior/afs_directories/espresso/code/multi-instance-mask-rcnn-extension/output/logs/train/train_2021-06-17-095941_VCS-2dbaca2_MAX_ITR-100000_HEAD_TYPE-None/model_checkpoints/model_000000.pth.tar\"\n",
    "# Custom\n",
    "config_filepath = f\"/home/adelgior/afs_directories/espresso/code/multi-instance-mask-rcnn-extension/output/logs/train/train_2021-06-16-154242_VCS-f165af5_MAX_ITR-100000_HEAD_TYPE-custom_MATCH-0/config.yaml\"\n",
    "model_checkpoint = f\"/home/adelgior/afs_directories/espresso/code/multi-instance-mask-rcnn-extension/output/logs/train/train_2021-06-16-154242_VCS-f165af5_MAX_ITR-100000_HEAD_TYPE-custom_MATCH-0/model_checkpoints/model_000000.pth.tar\"\n",
    "\n",
    "impth = \"/home/adelgior/afs_directories/kalman/data/datasets/coco2017/images/val2017/000000000139.jpg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/allie/afs_directories/kalman/code/multi-instance-mask-rcnn-extension\n"
     ]
    }
   ],
   "source": [
    "%cd /home/adelgior/afs_directories/kalman/code/multi-instance-mask-rcnn-extension/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# noinspection PyUnresolvedReferences\n",
    "from multimaskextension.model import multi_roi_heads_apd\n",
    "# noinspection PyUnresolvedReferences\n",
    "from multimaskextension.data import registryextension\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "## Later objectives:\n",
    "# Use this on the Kitchen dataset\n",
    "# Change the training loss to re-learn the instance generation.\n",
    "import time\n",
    "import torch.distributed\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.evaluation.evaluator import inference_context\n",
    "import detectron2.data.transforms as T\n",
    "import pickle\n",
    "\n",
    "from multimaskextension.train import script_utils\n",
    "from multimaskextension.train import script_utils\n",
    "from multimaskextension.train.script_utils import get_maskrcnn_cfg, DETECTRON_REPO\n",
    "from multimaskextension.analysis.vis_utils import cv2_imshow, FigExporter\n",
    "from multimaskextension.train.trainer_apd import Trainer_APD\n",
    "\n",
    "import local_pyutils\n",
    "\n",
    "def dbprint(*args, **kwargs):\n",
    "    print(*args, **kwargs)\n",
    "\n",
    "def get_model_input(original_image):\n",
    "    transform_gen = T.ResizeShortestEdge(\n",
    "                [cfg.INPUT.MIN_SIZE_TEST, cfg.INPUT.MIN_SIZE_TEST], cfg.INPUT.MAX_SIZE_TEST\n",
    "            )\n",
    "    if cfg.INPUT.FORMAT == \"RGB\":\n",
    "        # whether the model expects BGR inputs or RGB\n",
    "        original_image = original_image[:, :, ::-1]\n",
    "    height, width = original_image.shape[:2]\n",
    "    image = transform_gen.get_transform(original_image).apply_image(original_image)\n",
    "    image = torch.as_tensor(image.astype(\"float32\").transpose(2, 0, 1))\n",
    "    inputs = {\"image\": image, \"height\": height, \"width\": width}\n",
    "    return inputs\n",
    "\n",
    "def visualize(im, outputs, name='prediction', mask_name='pred_masks'):\n",
    "    # d. Visualize and export Mask R-CNN predictions\n",
    "    from detectron2.utils.visualizer import Visualizer\n",
    "    from detectron2.data import MetadataCatalog\n",
    "    v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "    outputs[\"instances\"].pred_masks = getattr(outputs['instances'], mask_name)\n",
    "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    cv2_imshow(v.get_image()[:, :, ::-1])\n",
    "    exporter.export_gcf(name)\n",
    "\n",
    "def detach_outputs(outputs):\n",
    "    for f in outputs['instances']._fields:\n",
    "        t = getattr(outputs['instances'], f)\n",
    "        if torch.is_tensor(t):\n",
    "            if t.requires_grad:\n",
    "                t = t.detach()\n",
    "        else:\n",
    "            if t.tensor.requires_grad:\n",
    "                t.tensor = t.tensor.detach()\n",
    "                \n",
    "def activate_head_type(model, head_type):\n",
    "    model.roi_heads.active_mask_head = head_type\n",
    "    if head_type == 'custom':\n",
    "        assert type(model.roi_heads.mask_heads[model.roi_heads.active_mask_head]) is \\\n",
    "               CustomMaskRCNNConvUpsampleHeadAPD, 'Not using custom head; head type is {}'.format(type(\n",
    "            model.roi_heads.mask_heads[model.roi_heads.active_mask_head]))\n",
    "    else:\n",
    "        assert type(model.roi_heads.mask_heads[model.roi_heads.active_mask_head]) \\\n",
    "               is not CustomMaskRCNNConvUpsampleHeadAPD\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model setup mimicking training behavior\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from multimaskextension.train.script_utils import Timer\n",
    "from detectron2.modeling import build_model\n",
    "\n",
    "def build_model_without_dataloader(cfg, checkpoint_file):\n",
    "    with Timer('Building model'):\n",
    "        model = build_model(cfg)\n",
    "\n",
    "    checkpointer = DetectionCheckpointer(model)\n",
    "    checkpointer.load(cfg.MODEL.WEIGHTS)\n",
    "\n",
    "    transform_gen = T.ResizeShortestEdge(\n",
    "        [cfg.INPUT.MIN_SIZE_TEST, cfg.INPUT.MIN_SIZE_TEST], cfg.INPUT.MAX_SIZE_TEST\n",
    "    )\n",
    "\n",
    "    input_format = cfg.INPUT.FORMAT\n",
    "    assert input_format in [\"RGB\", \"BGR\"], input_format\n",
    "\n",
    "    if checkpoint_file is not None:\n",
    "        assert os.path.exists(checkpoint_file)\n",
    "        state = torch.load(checkpoint_file)\n",
    "        for key, value in state.items():\n",
    "            if key == 'model_state_dict' or key == 'model':\n",
    "                model.load_state_dict(value)\n",
    "    return model\n",
    "        \n",
    "def build_model_with_dataloader(cfg, checkpoint_resume):\n",
    "    output_dir = '/tmp/'\n",
    "    trainer = Trainer_APD(cfg, out_dir=output_dir, interval_validate=1000, n_model_checkpoints=20,\n",
    "                          checkpoint_resume=checkpoint_resume)\n",
    "    return trainer.model\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running setup...\n",
      "Full config saved to /tmp/config.yaml\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output_dir = '/tmp/'\n",
    "resume_logdir = None\n",
    "print('Running setup...')\n",
    "cfg = script_utils.get_custom_maskrcnn_cfg(config_filepath)\n",
    "\n",
    "head_type = cfg.MODEL.ROI_MASK_HEAD.INIT_ACTIVATED_MASK_HEAD \\\n",
    "    if cfg.MODEL.ROI_HEADS.NAME != 'StandardROIHeads' else None\n",
    "config_dictionary = {'max_itr': cfg.SOLVER.MAX_ITER, 'head_type': head_type}\n",
    "if head_type == 'custom':\n",
    "    config_dictionary.update({'match': int(cfg.MODEL.ROI_MASK_HEAD.MATCHING_LOSS)})\n",
    "\n",
    "if resume_logdir is not None:\n",
    "    assert os.path.exists(os.path.join(output_dir, 'config.yaml'))\n",
    "    config_outpath = os.path.join(output_dir, \"config_resume.yaml\")\n",
    "else:\n",
    "    config_outpath = os.path.join(output_dir, \"config.yaml\")\n",
    "\n",
    "with open(config_outpath, \"w\") as f:\n",
    "    f.write(cfg.dump())\n",
    "print(\"Full config saved to {}\".format(os.path.abspath(config_outpath)))\n",
    "checkpoint_resume = None if resume_logdir is None else os.path.join(resume_logdir, rel_model_pth)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Building model]\n",
      "Elapsed: 0.4307868480682373\n",
      "[Building model]\n",
      "Elapsed: 0.47775721549987793\n",
      "All states same between modela and model b\n"
     ]
    }
   ],
   "source": [
    "SEED = 0\n",
    "import torch\n",
    "torch.manual_seed(SEED)\n",
    "import random\n",
    "random.seed(SEED)\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "model1 = build_model_without_dataloader(cfg, checkpoint_resume)\n",
    "\n",
    "SEED = 0\n",
    "import torch\n",
    "torch.manual_seed(SEED)\n",
    "import random\n",
    "random.seed(SEED)\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "model2 = build_model_without_dataloader(cfg, checkpoint_resume)\n",
    "\n",
    "modela = model1\n",
    "modelb = model2\n",
    "\n",
    "assert set(modela.state_dict().keys()) == set(modelb.state_dict().keys())\n",
    "mismatched_states = []\n",
    "for k in modela.state_dict().keys():\n",
    "    if not (modela.state_dict()[k] == modelb.state_dict()[k]).all():\n",
    "        mismatched_states.append(k)\n",
    "#         print(k)\n",
    "if len(mismatched_states) == 0:\n",
    "    print('All states same between modela and model b')\n",
    "else:\n",
    "    print('Mismatched states')\n",
    "    print(mismatched_states)\n",
    "# model2 = build_model_with_dataloader(cfg, checkpoint_resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Building model]\n",
      "Elapsed: 0.43318629264831543\n",
      "[Building model]\n",
      "Elapsed: 0.43639445304870605\n",
      "All states same between modela and model b\n",
      "tensor(40960, device='cuda:0') 40960\n"
     ]
    }
   ],
   "source": [
    "SEED = 0\n",
    "import torch\n",
    "torch.manual_seed(SEED)\n",
    "import random\n",
    "random.seed(SEED)\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "model1 = build_model_without_dataloader(cfg, checkpoint_resume)\n",
    "\n",
    "SEED = 0\n",
    "import torch\n",
    "torch.manual_seed(SEED)\n",
    "import random\n",
    "random.seed(SEED)\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "model2 = build_model_without_dataloader(cfg, checkpoint_resume)\n",
    "\n",
    "modela = model1\n",
    "modelb = model2\n",
    "\n",
    "assert set(modela.state_dict().keys()) == set(modelb.state_dict().keys())\n",
    "mismatched_states = []\n",
    "for k in modela.state_dict().keys():\n",
    "    if not (modela.state_dict()[k] == modelb.state_dict()[k]).all():\n",
    "        mismatched_states.append(k)\n",
    "#         print(k)\n",
    "if len(mismatched_states) == 0:\n",
    "    print('All states same between modela and model b')\n",
    "else:\n",
    "    print('Mismatched states')\n",
    "    print(mismatched_states)\n",
    "print((modela.state_dict()['roi_heads.custom_mask_head.predictor.weight'] == modelb.state_dict()['roi_heads.custom_mask_head.predictor.weight']).sum(), modelb.state_dict()['roi_heads.custom_mask_head.predictor.weight'].numel())\n",
    "# model2 = build_model_with_dataloader(cfg, checkpoint_resume)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([160, 256, 1, 1])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modela.state_dict()['roi_heads.custom_mask_head.predictor.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roi_heads.box_head.fc1.weight \t\t torch.Size([1024, 12544])\n",
      "roi_heads.box_head.fc1.bias \t\t torch.Size([1024])\n",
      "roi_heads.box_head.fc2.weight \t\t torch.Size([1024, 1024])\n",
      "roi_heads.box_head.fc2.bias \t\t torch.Size([1024])\n",
      "roi_heads.box_predictor.cls_score.weight \t\t torch.Size([81, 1024])\n",
      "roi_heads.box_predictor.cls_score.bias \t\t torch.Size([81])\n",
      "roi_heads.box_predictor.bbox_pred.weight \t\t torch.Size([320, 1024])\n",
      "roi_heads.box_predictor.bbox_pred.bias \t\t torch.Size([320])\n",
      "roi_heads.standard_mask_head.mask_fcn1.weight \t\t torch.Size([256, 256, 3, 3])\n",
      "roi_heads.standard_mask_head.mask_fcn1.bias \t\t torch.Size([256])\n",
      "roi_heads.standard_mask_head.mask_fcn2.weight \t\t torch.Size([256, 256, 3, 3])\n",
      "roi_heads.standard_mask_head.mask_fcn2.bias \t\t torch.Size([256])\n",
      "roi_heads.standard_mask_head.mask_fcn3.weight \t\t torch.Size([256, 256, 3, 3])\n",
      "roi_heads.standard_mask_head.mask_fcn3.bias \t\t torch.Size([256])\n",
      "roi_heads.standard_mask_head.mask_fcn4.weight \t\t torch.Size([256, 256, 3, 3])\n",
      "roi_heads.standard_mask_head.mask_fcn4.bias \t\t torch.Size([256])\n",
      "roi_heads.standard_mask_head.deconv.weight \t\t torch.Size([256, 256, 2, 2])\n",
      "roi_heads.standard_mask_head.deconv.bias \t\t torch.Size([256])\n",
      "roi_heads.standard_mask_head.predictor.weight \t\t torch.Size([80, 256, 1, 1])\n",
      "roi_heads.standard_mask_head.predictor.bias \t\t torch.Size([80])\n",
      "roi_heads.custom_mask_head.mask_fcn1.weight \t\t torch.Size([256, 256, 3, 3])\n",
      "roi_heads.custom_mask_head.mask_fcn1.bias \t\t torch.Size([256])\n",
      "roi_heads.custom_mask_head.mask_fcn2.weight \t\t torch.Size([256, 256, 3, 3])\n",
      "roi_heads.custom_mask_head.mask_fcn2.bias \t\t torch.Size([256])\n",
      "roi_heads.custom_mask_head.mask_fcn3.weight \t\t torch.Size([256, 256, 3, 3])\n",
      "roi_heads.custom_mask_head.mask_fcn3.bias \t\t torch.Size([256])\n",
      "roi_heads.custom_mask_head.mask_fcn4.weight \t\t torch.Size([256, 256, 3, 3])\n",
      "roi_heads.custom_mask_head.mask_fcn4.bias \t\t torch.Size([256])\n",
      "roi_heads.custom_mask_head.deconv.weight \t\t torch.Size([256, 256, 2, 2])\n",
      "roi_heads.custom_mask_head.deconv.bias \t\t torch.Size([256])\n",
      "roi_heads.custom_mask_head.predictor.weight \t\t torch.Size([160, 256, 1, 1])\n",
      "roi_heads.custom_mask_head.predictor.bias \t\t torch.Size([160])\n"
     ]
    }
   ],
   "source": [
    "for k in [k for k in modela.state_dict() if k.startswith('roi_heads')]:\n",
    "    print(k, '\\t\\t', modela.state_dict()[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "import torch\n",
    "torch.manual_seed(SEED)\n",
    "import random\n",
    "random.seed(SEED)\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "model1 = build_model_without_dataloader(cfg, checkpoint_resume)\n",
    "\n",
    "SEED = 0\n",
    "import torch\n",
    "torch.manual_seed(SEED)\n",
    "import random\n",
    "random.seed(SEED)\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "model2 = build_model_with_dataloader(cfg, checkpoint_resume)\n",
    "\n",
    "modela = model1\n",
    "modelb = model2\n",
    "\n",
    "assert set(modela.state_dict().keys()) == set(modelb.state_dict().keys())\n",
    "mismatched_states = []\n",
    "for k in modela.state_dict().keys():\n",
    "    if not (modela.state_dict()[k] == modelb.state_dict()[k]).all():\n",
    "        mismatched_states.append(k)\n",
    "#         print(k)\n",
    "if len(mismatched_states) == 0:\n",
    "    print('All states same between modela and model b')\n",
    "else:\n",
    "    print('Mismatched states')\n",
    "    print(mismatched_states)\n",
    "# model2 = build_model_with_dataloader(cfg, checkpoint_resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "import torch\n",
    "torch.manual_seed(SEED)\n",
    "import random\n",
    "random.seed(SEED)\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "model1 = build_model_without_dataloader(cfg, checkpoint_resume)\n",
    "\n",
    "SEED = 0\n",
    "import torch\n",
    "torch.manual_seed(SEED)\n",
    "import random\n",
    "random.seed(SEED)\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "model2 = build_model_without_dataloader(cfg, checkpoint_resume)\n",
    "\n",
    "modela = model1\n",
    "modelb = model2\n",
    "\n",
    "assert set(modela.state_dict().keys()) == set(modelb.state_dict().keys())\n",
    "mismatched_states = []\n",
    "for k in modela.state_dict().keys():\n",
    "    if not (modela.state_dict()[k] == modelb.state_dict()[k]).all():\n",
    "        mismatched_states.append(k)\n",
    "#         print(k)\n",
    "if len(mismatched_states) == 0:\n",
    "    print('All states same between modela and model b')\n",
    "else:\n",
    "    print('Mismatched states')\n",
    "    print(mismatched_states)\n",
    "# model2 = build_model_with_dataloader(cfg, checkpoint_resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "import torch\n",
    "torch.manual_seed(SEED)\n",
    "import random\n",
    "random.seed(SEED)\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "model1 = build_model_without_dataloader(cfg, checkpoint_resume)\n",
    "\n",
    "SEED = 50\n",
    "import torch\n",
    "torch.manual_seed(SEED)\n",
    "import random\n",
    "random.seed(SEED)\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "model2 = build_model_with_dataloader(cfg, checkpoint_resume)\n",
    "\n",
    "modela = model1\n",
    "modelb = model2\n",
    "\n",
    "assert set(modela.state_dict().keys()) == set(modelb.state_dict().keys())\n",
    "mismatched_states = []\n",
    "for k in modela.state_dict().keys():\n",
    "    if not (modela.state_dict()[k] == modelb.state_dict()[k]).all():\n",
    "        mismatched_states.append(k)\n",
    "#         print(k)\n",
    "if len(mismatched_states) == 0:\n",
    "    print('All states same between modela and model b')\n",
    "else:\n",
    "    print('Mismatched states')\n",
    "    print(mismatched_states)\n",
    "# model2 = build_model_with_dataloader(cfg, checkpoint_resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build_model_without_dataloader produces the same model state dictionary regardless of the random seed set.\n",
    "# build_model_without_dataloader produces the same model state dictionary when random seed it set the same.\n",
    "#'roi_heads.custom_mask_head.predictor.weight'\n",
    "\n",
    "modela = model1\n",
    "modelb = model2\n",
    "\n",
    "assert set(modela.state_dict().keys()) == set(modelb.state_dict().keys())\n",
    "mismatched_states = []\n",
    "for k in modela.state_dict().keys():\n",
    "    if not (modela.state_dict()[k] == modelb.state_dict()[k]).all():\n",
    "        mismatched_states.append(k)\n",
    "#         print(k)\n",
    "if len(mismatched_states) == 0:\n",
    "    print('All states same between modela and model b')\n",
    "else:\n",
    "    print('Mismatched states')\n",
    "    print(mismatched_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(modela.state_dict()['roi_heads.custom_mask_head.predictor.weight'] == modelb.state_dict()['roi_heads.custom_mask_head.predictor.weight']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model1\n",
    "\n",
    "if not cfg.MODEL.ROI_HEADS.NAME == 'StandardROIHeads':\n",
    "    activate_head_type(model, head_type)\n",
    "\n",
    "# I. Load pre-existing Mask R-CNN model\n",
    "# a. Get example image to work with\n",
    "cpu = 1\n",
    "\n",
    "im = cv2.imread(impth)\n",
    "cv2_imshow(im)\n",
    "exporter = FigExporter(workspace_dir='/home/allie/workspace/images/')\n",
    "exporter.export_gcf('input')\n",
    "\n",
    "# c. Get Mask R-CNN predictions (and print boxes)\n",
    "inputs = get_model_input(im)\n",
    "outputs = model([inputs])[0]\n",
    "detach_outputs(outputs)\n",
    "\n",
    "original_image = im\n",
    "mask_name = 'pred_masks1'\n",
    "# d. Visualize and export Mask R-CNN predictions\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "outputs[\"instances\"].pred_masks = getattr(outputs['instances'], mask_name)\n",
    "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "cv2_imshow(v.get_image()[:, :, ::-1])\n",
    "exporter.export_gcf(name)\n",
    "\n",
    "# visualize(im, outputs, 'pred_masks1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'model_final_f10217.pkl'\n",
    "initialization_file = os.path.join('/home/adelgior/afs_directories/espresso/data/models/detectron_model_zoo/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/', os.path.basename(cfg.MODEL.WEIGHTS))\n",
    "\n",
    "print('Loading state dict')\n",
    "cpt_state = torch.load(model_checkpoint, map_location=torch.device('cpu')) if cpu \\\n",
    "    else torch.load(model_checkpoint)\n",
    "init_state = pickle.load(open(initialization_file, 'rb'))\n",
    "init_state['model'] = {k: torch.Tensor(v) for k, v in init_state['model'].items()}\n",
    "# model_state = cpt_state['model_state_dict']\n",
    "model_state = init_state['model']\n",
    "model.load_state_dict(model_state)\n",
    "model.load_checkpoint()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg = get_maskrcnn_cfg(config_filepath)\n",
    "model = Trainer_APD.build_model(cfg)\n",
    "model.eval()\n",
    "print('Loading state dict')\n",
    "cpt_state = torch.load(model_checkpoint, map_location=torch.device('cpu')) if cpu \\\n",
    "    else torch.load(model_checkpoint)\n",
    "init_state = pickle.load(open(initialization_file, 'rb'))\n",
    "init_state['model'] = {k: torch.Tensor(v) for k, v in init_state['model'].items()}\n",
    "# model_state = cpt_state['model_state_dict']\n",
    "model_state = init_state['model']\n",
    "model.load_state_dict(model_state)\n",
    "model.load_checkpoint()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cfg = get_maskrcnn_cfg(config_filepath)\n",
    "# cfg.MODEL.DEVICE = 'cpu'\n",
    "# model = Trainer_APD.build_model(cfg)\n",
    "# model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pprint import pprint\n",
    "# pprint(outputs[\"instances\"].pred_classes)\n",
    "# pprint(outputs[\"instances\"].pred_boxes)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
