{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Goal: create data structures / loops for xent calculation\"\"\"\n",
    "import torch\n",
    "d=torch.load('tmp_matching_loss.pt')\n",
    "\n",
    "pred_mask_logits = d['pred_mask_logits']\n",
    "instances = d['instances']\n",
    "n_masks_per_roi = d['n_masks_per_roi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([34, 28, 28])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_images = len(instances)\n",
    "assert n_images == 1\n",
    "\n",
    "mask_side_len = pred_mask_logits.size(2)\n",
    "total_num_masks = pred_mask_logits.size(0)\n",
    "\n",
    "instances_per_image = instances[0]\n",
    "\n",
    "gt_1 = instances_per_image.gt_masks.crop_and_resize(\n",
    "         instances_per_image.proposal_boxes.tensor, mask_side_len).to(device=pred_mask_logits.device)\n",
    "gt_2 = instances_per_image.gt_second_best_masks.crop_and_resize(\n",
    "         instances_per_image.proposal_boxes.tensor, mask_side_len).to(device=pred_mask_logits.device) \n",
    "\n",
    "gt_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_pairs = [torch.stack([g1, g2]) for g1, g2 in zip(gt_1, gt_2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([28, 28]), torch.Size([28, 28]))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = torch.arange(total_num_masks)\n",
    "gt_classes = instances_per_image.gt_classes.to(dtype=torch.int64)\n",
    "\n",
    "pred_mask_pairs = [[p[i::n_masks_per_roi, :, :][gt_class] for i in range(n_masks_per_roi)] for p, gt_class in zip(pred_mask_logits, gt_classes)]\n",
    "\n",
    "len(pred_mask_pairs)\n",
    "len(pred_mask_pairs[0])\n",
    "pred_mask_pairs[0][0].shape, pred_mask_pairs[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0671, 4.0934],\n",
      "        [0.6836, 0.7042]], grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "instances_per_image[idx:(idx+1)]\n",
    "\n",
    "\n",
    "for idx, (gt_pair, pred_pair) in enumerate(zip(gt_pairs, pred_mask_pairs)):\n",
    "    xent_losses = torch.zeros((len(gt_pair), len(pred_pair)))\n",
    "    for i, pred in enumerate(pred_pair):\n",
    "        for j, gt in enumerate(gt_pair):\n",
    "            xent_losses[i, j] = maskwise_mask_loss = F.binary_cross_entropy_with_logits(\n",
    "                pred, gt.to(dtype=torch.float32), reduction='mean')\n",
    "\n",
    "print(xent_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7714, grad_fn=<AddBackward0>)\n",
      "tensor(4.7770, grad_fn=<AddBackward0>)\n",
      "tensor([[0.0671, 4.0934],\n",
      "        [0.6836, 0.7042]], grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from scipy import optimize\n",
    "import numpy as np\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "def solve_matching_problem(cost_tensor: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Returns matching assignment, sorted by row index.\n",
    "    \"\"\"\n",
    "    if torch is not None:\n",
    "        assert type(cost_tensor) is np.ndarray or torch.is_tensor(cost_tensor)\n",
    "    else:\n",
    "        assert type(cost_tensor) is np.ndarray\n",
    "    cost_tensor_for_assignment = cost_tensor.detach() if cost_tensor.requires_grad else cost_tensor\n",
    "    row_ind, col_ind = optimize.linear_sum_assignment(cost_tensor_for_assignment)\n",
    "    ind_idxs_sorted_by_row = np.argsort(row_ind)\n",
    "    col_ind = [col_ind[idx] for idx in ind_idxs_sorted_by_row]\n",
    "    return col_ind\n",
    "\n",
    "match_cols = solve_matching_problem(xent_losses)\n",
    "print(sum(xent_losses[[0, 1], match_cols]))\n",
    "print(sum(xent_losses[[0, 1], [1 - m for m in match_cols]]))\n",
    "print(xent_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Goal: get pairwise xent\"\"\"\n",
    "# import torch\n",
    "# d=torch.load('tmp_pairwise_xent.pt')\n",
    "# logit_sets, gt_sets, instances = d['logit_sets'], d['gt_sets'], d['instances'] # length of each is # images\n",
    "# gt_sets = [\n",
    "#     [[i.gt_masks[idx:(idx+1)], i.gt_second_best_masks[idx:(idx+1)]] for idx in range(len(i))]\n",
    "#     for i in instances]\n",
    "# gt_matching_sets = [\n",
    "#     [[i.gt_masks[idx], i.gt_second_best_masks[idx]] for idx in range(len(i))]\n",
    "#     for i in instances]\n",
    "\n",
    "\n",
    "# logit_matching_sets = list(zip(*logit_sets))\n",
    "\n",
    "# for z in (logit_matching_sets, gt_matching_sets): # (z1, z2):\n",
    "#     el = z\n",
    "#     descr = ''\n",
    "#     tab = 1\n",
    "#     while not torch.is_tensor(el) and tab < 6:\n",
    "#         if isinstance(el, tuple) or isinstance(el, list):\n",
    "#             descr += \"\\t\".join('' for _ in range(tab)) + f\"{type(el).__name__} of length {len(el)}.  Each element is:\\n\"\n",
    "#         elif hasattr(el, '__len__'):\n",
    "#             descr += \"\\t\".join('' for _ in range(tab)) + f\"{type(el).__name__} of length {len(el)}.  Each element is:\\n\"\n",
    "#         else:\n",
    "#             break\n",
    "#         old_el = el\n",
    "#         el = el[0]\n",
    "#         tab += 1\n",
    "#     if torch.is_tensor(el):\n",
    "#         descr += \"\\t\".join('' for _ in range(tab)) + f\"{type(el).__name__} of shape {el.shape}.\"\n",
    "#     else:\n",
    "#         descr += \"\\t\".join('' for _ in range(tab)) + f\"{type(el).__name__}\"\n",
    "\n",
    "#     print(descr)\n",
    "\n",
    "# #     I have (logit_sets):\n",
    "# #         List[Tensor(34,80,28,28), Tensor(34,80,28,28)]\n",
    "# #     I need (zip(*logit_sets)):\n",
    "# #           List[Tuple(Tensor(80,28,28), Tensor(80,28,28)), ...x34]\n",
    "# #     I have (gt_sets):\n",
    "# #         List[[PolygonMasks(34)], [PolygonMasks(34)]]\n",
    "# #     I need:\n",
    "# #         List[ [Tuple(PolygonMasks(1), PolygonMasks(1)), ...x34] x#_images]\n",
    "# instances_per_image = instances[0]\n",
    "# gt_matching_sets = [\n",
    "#     [[i.gt_masks[idx], i.gt_second_best_masks[idx]] for idx in range(len(i))]\n",
    "#     for i in instances]\n",
    "# gt_matching_sets_per_image = gt_matching_sets[0]\n",
    "# for gt_tuple in gt_matching_sets_per_image:\n",
    "#     print(len(gt_tuple), type(gt_tuple[0]), len(gt_tuple[0]))\n",
    "\n",
    "# pred_mask_logit_matching_sets_per_image = list(zip(*logit_sets))    \n",
    "# for s in pred_mask_logit_matching_sets_per_image:\n",
    "#     print(len(s), type(s[0]), len(s[0]))\n",
    "\n",
    "\n",
    "# pred_mask_logits = logit_sets[0]\n",
    "# gt_masks_raw = gt_sets[0]\n",
    "\n",
    "# cls_agnostic_mask = pred_mask_logits.size(1) == 1\n",
    "# total_num_masks = pred_mask_logits.size(0)\n",
    "# mask_side_len = pred_mask_logits.size(2)\n",
    "# assert pred_mask_logits.size(2) == pred_mask_logits.size(3), \"Mask prediction must be square!\"\n",
    "\n",
    "# gt_classes = []\n",
    "# gt_masks = []\n",
    "# for instances_per_image, gt_masks_per_image in zip(instances, gt_masks_raw):\n",
    "#     if len(instances_per_image) == 0:\n",
    "#         continue\n",
    "#     if not cls_agnostic_mask:\n",
    "#         gt_classes_per_image = instances_per_image.gt_classes.to(dtype=torch.int64)\n",
    "#         gt_classes.append(gt_classes_per_image)\n",
    "\n",
    "#     gt_masks_per_image = gt_masks_per_image.crop_and_resize(\n",
    "#         instances_per_image.proposal_boxes.tensor, mask_side_len).to(device=pred_mask_logits.device)\n",
    "#     # A tensor of shape (N, M, M), N=#instances in the image; M=mask_side_len\n",
    "#     gt_masks.append(gt_masks_per_image)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch4_python3",
   "language": "python",
   "name": "pytorch4_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
